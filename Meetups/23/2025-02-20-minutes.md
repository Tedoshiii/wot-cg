# Meeting Minutes

## info

:date: **Date:** 20 February 2024

### :bust_in_silhouette: Participants

<!-- This list will copied over from the meeting tool -->
- Ege Korkan
- Cristiano Aguzzi
- Andreas Eberhart
- Vignesh Vaidyanathan
- Denis Ioan
- Henk (hiveot)
- Kunihiko Toumura
- Tomoaki Mizushima
- David Ezell
- Jan Romann
- Christian Paul
- Mark Scott
- Christian Glomb
- MOHAMED ZENADI
- Tatiana Mangels
- Daniel Peintner
- York Schmidtke
- Alexander Schmidt

:writing_hand: **Scribe:** Cris

----

## Meetup

### Introduction

Ege: 24th meetup first of 2025!

### News

Ege: on march 10th will be a new event about how to use WoT in mixed reality environments.

Ege: more are in the process to be planned

### Meetup Presentation

Ege: with us we have Andreas Eberhart, he has extensive business and developer experience. Currently he is CEO of Dashjoin.

Andreas: Thank you for introduction. This is a joint work with Ege.

Andreas: We started a joint work talking about JSON Schema and WoT presented at API days in Paris. We have the code available.

Andreas: We have billions of devices on the internet. It is important to manage devices in a generic way. On the other hand, you want to personalize features for some specific use cases.

Andreas: Security is important. In this scenario, we build a local development platform and open-source it. It provides a lot of basic features which helped us to build the WoT manager.

Andreas: We used OpenID for user management. In southbound, we have the actual WoT interaction. Right now, we support only REST API.

Andreas: PostgreSQL is used to store Thing Descriptions.

#### Discovery

Andreas: The process starts with a URL but supports a Role Based Access Control (RBAC) to protect selected devices.

#### Properties and Actions

Andreas: We generated device pages, where you can inspect low level code (based on JSONata) and control devices using UI (generated on the fly with JSON Schema).

Andreas: Forms are generated by interpreting the TD.

#### Background Knowledge

Andreas: In IoT contexts, having additional datasources is critical to implement use-case-specific business logic. That's why we have a built-in mechanism to store contextual information and link back to TDs.

Andreas: We support semantic data harmonization to enrich basic contextual information.

#### Natural Language Commands

Andreas: We developed a way to command different devices using an open source LLM. The model is capable of choosing the right input for different actions just by using Thing Description data.

Andreas: We can then develop an Agent framework to satisfy a certain goal.

#### Demo

Andreas: [Source code is available](https://github.com/dashjoin/djapp-wot) and we have [the corresponding paper](https://github.com/dashjoin/djapp-wot/blob/main/paper.md), too.

> Andreas shows the UI of the demo

Andreas: Voice-to-text and code generation are supported. You can have dashboards, too.

### Question

Ege: Could you explain your process of getting to something working?

Andreas: The platform is data driven. We start by loading data. You can create tables very easily once you have data in the DB. Everything has a page (much like a semantic Wikipedia). You can customize any page. Everything can be committed to GitHub and personalized.

Ege: Which open source tools did you use? What are the tools and libraries that make it click?

Andreas: Thanks to standards and JSON Schema.

Henk: What discovery mechanism did you use? Very impressive presentation, and I can tell there was a lot of work.

Andreas: To discover a new thing, I will just input the Thing Description URL. In terms of the protocols, we only support the easy stuff â€” URL and JSON.

Henk: Are you planning any "automatic loading" of TDs?

Andreas: We have a registry CSV or a north bound API.

Andreas: There are devices protected by password. We added a small extension to TD to express the role and the accounts who can use the device.

Henk: If you have 5 people with different roles, can they only access different parts of the system? or they can't do some actions?

Andreas: On the database level, there is a table which contains all the things, and two other tables connected with Properties and Actions. We can lock different parts of these tables to different roles. We can support hiding or revealing Properties or Actions you can view and use.

Andreas: We are interested working with the community and love to hear more from you. Please use our GitHub repository. The project is just beginning!

Ege: Any inputs for the standardization process?

Andreas: We are still working on some of the features. But from the research perspective is semantic harmonization. It would be wonderful to use JSON-LD and semantic more to automate this process.

Vignesh: When there is something that we need to use but it is not in the standard, is it okay to be added in the TD?

Andreas: We ignore them, so they don't show in the UI. You can make an extension of the WoT manager to use this information.

Cris: Are you storing timeseries in the PostgreSQL database?

Andreas: We are storing the latest value, but it is easy to change.

Cris: Is it polling based?

Andreas: Yes.

Ege: Interesting point. Describing which properties need to be stored in a timeseries DB could be something we can do in the specification.

Andreas: Whether to keep the value or not is definitely not device specific.

Andreas: What do you think about the AI agent? For me, the interesting part is that you don't have to think about different application context.

Ege: It is interesting that you showed how you can achieve a good interaction with the AI with off-the-shelf tools without reinventing any AI specification. In this case, you can probably use quite small AI models to achieve good results.

Andreas: We pre-process the TD before sending it to the LLM.

Cris: What are the limitations?

Andreas: In complex contexts, it gets messy.

Cris: Are you polishing the AI output?

Andreas: Currently it is directly connected.

Cris: Do you have some Role-based access control for AI agents?

Andreas: User privileges are in there, but they use a different key.

Ege: Can using AI prompts help solve the data augmentation problem?

Andreas: Not really, the data mapping should be very precise. But it could be a good idea.

## :ballot_box_with_check: Resolutions

None

## :exclamation: Action Items

None

## :envelope_with_arrow: Feedbacks

- Expressing role-based Authentication is not possible in the standard so we had to add ourselves
- Frequency of change of a value is relevant for timeseries
