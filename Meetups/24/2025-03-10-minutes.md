# Meeting Minutes

:date: **Date:** 10 March 2025

## :bust_in_silhouette: Participants

<!-- This list will copied over from the meeting tool -->
- Ege Korkan
- Cristiano Aguzzi
- Fady Salama
- Michael Mccool
- Moisés Muñiz
- Kunihiko Toumura
- Tomoaki Mizushima
- Michael Koster
- Torbjörn Lahrin
- atsushi shimono
- Sandro Puccio
- York Schmidtke
- Daniel Peintner
- Matthias Meier
- Kay Koehle
- Frank Salzburger
- Reiner Mueller

:writing_hand: **Scribe:** Ege

----

## Introduction

Cris: Some news from the community and then the presentation

## Meetup Presentation

Fady: Our motivation is as follows. In a smart home you can use your smart phone. However, in the industry things like robots don't have nice interface.

Fady: If you go to a field, you have sensors on a field. You can only bring some devices with you.

Fady: We want to augment the user's experience so that they can interact with the environment around them.

Fady: We want to enable interactions with the environment in a seamless way for smart home, agriculture and industry.

Fady: We have developed HoloWoT. It can work with an XR headset. A QR code links to a TD, the headset fetches the TD and can interact with it.

Fady: Our application is fully inside the headset. It is composed of two parts, interaction and community.

Roman: We want to explain WoT first. These devices can use different protocols. With WoT we can use different protocols like HTTP, MQTT CoAP.

Roman: We have interaction affordances  named properties actions and events. Each affordance has a data schema that describes the concrete data payload needed.

Roman: Then we can use different protocols, like MQTT and HTTP in this example.

Roman: There are other building blocks of WoT as well.

Roman: We use Microsoft Hololens 2. It is an AR headset. You can see the real world together with the virtual overlay. It can track your eyes and your hand gestures. We know what you look at.

Roman: It also knows the environment. It scans it and you can place anchors in the world.

Roman: We are using Unity. It is for games but used heavily in AR. It uses C# scripts

Roman: We are also using MRTK from Microsoft. With it you can execute the same app in other headsets.

Fady: Now we know the development environment. So that means that we have to use C#. We started WoT.Net.

Fady: It can handle HTTP/S at the moment but can be extended in the future. It can use basic auth and digest tokens.

Fady: We have the core part which is just the interfaces. You can write bindings by implementing those interfaces.

Fady: Also, the data schema is mapped to the C# types. For example, we cannot have arrays with different types in it. It is a limitation.

Fady: With HTTP binding, we follow the node-wot architecture, like client and client factory for that binding.

Fady: In MRTK3, which is built on top of OpenXR, we can build this app to multiple headsets.

Fady: We have built prefab UI elements. They are closely related to the data schema and the operations to be done on the affordance.

Fady: Here is the workflow. You scan the QR code, the TD is fetched and displayed. The interactions are linked on the right and rendered without JSON.

> Shows the video

Fady: We wanted to go further. We want to build mashups. First we had to redo some changes to the UI.

Fady: We have separated the concerns and created different boxes/elements in a better UX

Fady: Regarding a mashup generation, we are using a factory simulator from Fischertechnik. Based on the object type, it would go through different processes.

Fady: Here we see the mashup being programmed and running. The hololens application is doing everything.

Fady: Here we are teasing how it can look like for robots. It can work with any robot.

## Discussion

Daniel: How can the user input credentials?

Fady: Worst case would be the keyboard but we think that a visual clue would be need.

Fady: Probably the user needs to auth with a provide to interact with all devices. Actually the Iris scanner can be used in a way. Using the keyboard is quite annoying.

McCool: Now that plumbing is done. The UI is quite text oriented. The UI should be more VR-ish or maybe even AR-ish where you pick up physical objects.

Fady: For the robots, we can leverage URDF standard to understand the joints and manipulate those.

McCool: For a temperature sensor, you would need semantic information right. Or AI to suggest annotations?

Fady: We would need a standard for this stuff. Maybe you need a state machine to describe possible interactions.

Fady: I have some prior work about using state machine to describe the physical interactions.

Cris: I think the initial results are great. We would need something like CSS for TDs. It is challenging for 2D already. Maybe an artist needs to create common 3D artifacts.

McCool: Semantics are not explicit. An LLM can generate annotations or choose from a list of annotations. Maybe we can just md-icons even.

Ege: Could you explain the motivation between the UI designs a bit more? What is the UX difference in XR apps compared to usual interfaces.

Fady: Scrolling - you could scroll outside of the scope. It is not easily to scroll for many users.

Fady: For objects, they need to be rendered.

Ege: For XR UIs, it seems we have different requirements. Users don't have a precise mouse cursor.

Cris: We have a similar issue in our implementation. For example, an enum list that is long needs to trigger search field.

McCool: Is speech input available?

Fady: Yes. You can select with your eyes. But all of that needs a team of people building that stuff.

Cris: With Microsoft, Apple also stopped the production of Vision Pro. What do you think about the future?

Fady: This is a niche domain in the end. I was thinking of looking at meta quest. Sadly, they do not allow image processing due to security reasons. So we cannot scan QR codes.

McCool: I think the big headsets are having issues but the lightweight ones are getting more popular. Displays are getting better. The real endgame would be the small ones and the heavy ones staying in dev mode.

Fady: I fully agree. They are developing advanced

Cris: Any challenges you face when porting to .Net? Now we have these interfaces available in different languages.

Fady: I find it hard when looking at these "old" languages. For example, "undefined" does not exist in C#. People use null in C# but that is not actually what we should use. "null" can actually be a value.

Cris: Web IDL has the limitations, which is what we use in the scripting api specification.

Daniel: In Java, at some point the void class was introduced. Do you have a similar concept?

Fady: Void exists. Sometimes you want to return undefined. or sometimes a union type is required by scripting api, which is not easy (or not possible at all).

## :envelope_with_arrow: Feedbacks

Fady: I find it hard when looking at these "old" languages. For example, "undefined" does not exist in C#. People use null in C# but that is not actually what we should use. "null" can actually be a value.
